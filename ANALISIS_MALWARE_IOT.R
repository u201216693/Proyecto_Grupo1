#--------------------------------------------------------------
# Para limpiar el workspace, por si hubiera algun dataset 
# o informacion cargada
rm(list = ls())

#--------------------------------------------------------------
# Para limpiar el ?rea de gr?ficos
dev.off()

#--------------------------------------------------------------
# Limpiar la consola
cat("\014")

options(scipen=999)
options(digits = 4)



# Cambiar el directorio de trabajo
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()


#############################
#  1. Descripci?n del caso  #
#############################

#Introduccion: ...
#Problema: ...

############################################
#  2. Exploraci?n y preparaci?n de datos   #
############################################

#  2.1. Identificaci?n de variables
#===================================

# Lectura de los datos 
capture_1 = "D:\\Proyecto_Grupo1\\Proyecto_Grupo1\\conn.log.labeled"
datos <- read.table(file=capture_1, header=FALSE, sep = "")
colnames(datos) <- c('ts',
                  'uid',
                  'id.orig_h',
                  'id.orig_p',
                  'id.resp_h',
                  'id.resp_p',
                  'proto',
                  'service',
                  'duration',
                  'orig_bytes',
                  'resp_bytes',
                  'conn_state',
                  'local_orig',
                  'local_resp',
                  'missed_bytes',
                  'history',
                  'orig_pkts',
                  'orig_ip_bytes',
                  'resp_pkts',
                  'resp_ip_bytes',
                  'tunnel_parents',
                  'label',
                  'detailed_label')

# Viendo la estructura de los datos - 23 variables iniciales y 1 008 748 registros
str(datos)
summary(datos)



# Evaluando la variable target label : "Benign" y "Malicious"
table(datos$label)
prop.table(table(datos$label))

# Evaluando la variable detailed_label
 table(datos$detailed_label)
 prop.table(table(datos$detailed_label))
 
 
 # Eliminando la columna de identificaci?n de la conexion (uid), no es relevante para nuestro estudio
 datos$uid <- NULL

#  2.2. Tratamiento de datos perdidos
#===================================

# Exploraci?n de datos perdidos con DataExplorer y VIM

library(DataExplorer)
plot_missing(datos)

# Reemplazamos para visualizar los valores nulos con tidyverse
library(tidyverse)
datos[datos == "-"] <- NA
datos[datos == "(empty)"] <- NA


plot_missing(datos)

# Impacto de los valores faltantes(missings)

#< 1%                           Trivial
#Entre 1 amenos del 5%          Manejable
#Entre el 5 a menos del 20%     Requiere m?todos sofisticados
#20% o m?s                      Perjudica las interpretaciones

# Eliminamos columnas con alto procentaje de datos faltantes(perjudica las interpretaciones)

# >90%
datos$service <- NULL
datos$tunnel_parents <- NULL
datos$local_resp <- NULL
datos$local_orig <- NULL


# visualizamos los valores nulos 
plot_missing(datos)

# Para ver cuantas filas tienen valores perdidos
rmiss <- which(rowSums(is.na(datos))!=0,arr.ind=T)
length(rmiss)

# Total de datos perdidos
sum(is.na(datos)) 

#Hay 819457 registros que tienen uno o mas datos perdidos, existen 2875596 datos perdidos.
#Se valida que hay registros que contienen m?s de un dato perdido es por ello la diferencia.

# Graficar la cantidad de valores perdidos, para visualizar la relacion entre variables
library(VIM)
graf_perdidos1 <- aggr(datos,prop = F, 
                       numbers = TRUE,
                       sortVars=T,
                       cex.axis=0.5)

# Eliminamos columna history describe el historial de conexi?n, no es relevante para nuestro estudio
datos$history <- NULL

# Eliminamos columna detailed_label describe el tipo de captura maliciosa,
# se tomar? como target la variable label, detailed_label no ser? considerada
datos$detailed_label <- NULL

# Eliminamos columna ts 
# describe la marca de tiempo de la captura(de manera correlativa y autoincremental)
datos$ts <- NULL

#  2.3. Imputacion de datos perdidos
#===================================

# Datos perdidos en la recoleccion de datos, mecanismo ?MCAR,MAR o MNAR?
# MCAR: Datos perdidos completamente aleatorio ... se recomienda imputacion, eliminar reducira el tama?o de la muestra, pero no ocasionara sesgo
# MAR:  Datos perdidos al azar ... se recomienda imputacion, no es ideal eliminar, puede conducir a sesgos
# MNAR: Datos perdidos no aleatorios...no se recomienda imputacion

# Escenario MNAR 
# Evaluando la variable duration
table(datos$duration)
prop.table(table(datos$duration))
summary(datos$duration)

#library(tidyr)
#datos%>%drop_na(duration)
# Reemplazamos los NAs con valor "0"
datos$duration[is.na(datos$duration)] <- "0"
#Convertimos a numerico
datos <- transform(datos,duration = as.numeric(duration))
datos <- transform(datos,orig_bytes = as.numeric(orig_bytes))
datos <- transform(datos,resp_bytes = as.numeric(resp_bytes))


# Evaluando la variable resp_bytes
table(datos$resp_bytes)
prop.table(table(datos$resp_bytes))
summary(datos$resp_bytes)

# Evaluando la variable orig_bytes
table(datos$orig_bytes)
prop.table(table(datos$orig_bytes))
summary(datos$orig_bytes)

# Evaluando la variable missed_bytes
table(datos$missed_bytes)
prop.table(table(datos$missed_bytes))
summary(datos$missed_bytes)

# eliminamos la variable missed_bytes 
datos$missed_bytes <- NULL

# Imputaci?n generalizada con el paquete DMwR
library(DMwR2)
# Funci?n centralImputation()
# Si la variable es num?rica (numeric o integer) reemplaza los
# valores faltantes con la mediana.
# Si la variable es categ?rica (factor) reemplaza los valores 
# faltantes con la moda. 
datos.ci <- centralImputation(datos)



# Evaluando la variable resp_bytes
table(datos.ci$resp_bytes)
prop.table(table(datos.ci$resp_bytes))
summary(datos.ci$resp_bytes)

# Evaluando la variable orig_bytes
table(datos.ci$orig_bytes)
prop.table(table(datos.ci$orig_bytes))
summary(datos.ci$orig_bytes)

# Tomando como referencia trabajos previos de deteccion de intrusos se eliminan features
# que incluyen ips y puertos
datos.ci$id.orig_h <- NULL
datos.ci$id.orig_p <- NULL
datos.ci$id.resp_h <- NULL
datos.ci$id.resp_p <- NULL

# Veamos la Correlaci?n devariables
df<-datos.ci
# la Correlaci?n se realizar? con las variables num?ricas
df$label <- NULL
df$conn_state <- NULL
df$proto <- NULL
# Veamos la Correlaci?n entre las variables num?ricas
summary(df)
df2.cor<-cor(df,method="pearson")
library(corrplot)
corrplot(df2.cor)

# Seg?n el gr?fico de correlaci?n, orig_pkts y orig_ip_bytes se correlacionan, 
# de manera similar con resp_pkts y resp_ip_bytes
datos.ci$orig_ip_bytes <- NULL
datos.ci$resp_ip_bytes <- NULL




#  2.4. Detecci?n de Outliers
#===================================
# veo como queda la imputaciÃ²n
str(datos.ci)
# Detecci?n de outliers univariados

# orig_pkts,se vavisualizar undiagrama de cajas
boxplot(datos.ci$orig_pkts,col="peru") # presenta outliers
outliers1 <- boxplot(datos.ci$orig_pkts,col="peru")$out # haremos un corte para elminar outliers
outliers1
length(outliers1) 
summary(outliers1)
 
 # no sale solouna linea,dadoque todoslosvaloresson 0

# eliminamos la variable missed_bytes 
datos.ci$missed_bytes <- NULL

# orig_pkts
boxplot(datos.ci$orig_pkts,col="peru") # presenta outliers
outliers1 <- boxplot(datos.ci$orig_pkts,col="peru")$out # haremos un corte para elminar outliers
outliers1
length(outliers1) 
summary(outliers1)
#hay que tratar de eliminar los outliers
library(dplyr)
sum(datos.ci$orig_pkts> 3) # veamos la cantidad de outliers segun el filtro , 8686 = 0.08%
datos.out1 <- datos.ci %>% filter(orig_pkts<=3) # se usa un filtro --antes 1008748

# resp_pkts
# --------------
boxplot(datos.out1$resp_pkts,col="peru") # 
outliers2 <- boxplot(datos.out1$resp_pkts,col="peru")$out # 
outliers2
length(outliers2) 
summary(outliers2)

sum(datos.out1$resp_pkts> 1) # veamos la cantidad de outliers segun el filtro 
datos.out2 <- datos.out1 %>% filter(resp_pkts<=1) # se usa un filtro --antes 

# duration
# --------------
boxplot(datos.out2$duration,col="peru") # 
outliers3 <- boxplot(datos.out2$duration,col="peru")$out # 
outliers3
length(outliers3) 
summary(outliers3)

sum(datos.out2$duration> 5) # veamos la cantidad de outliers segun el filtro 
datos.out3 <- datos.out2 %>% filter(duration<=5) # se usa un filtro --antes 



#  2.4. Normalizaci?n
#===================================
str(datos.out3)
summary(datos.out3)
plot_missing(datos.out3)

#  Recodificamos la variable duration de timedelta64 a segundos
datos.out3$duration <- datos.out3$duration*24*60*60

#Min-Max
#library(DMwR2)
#datos.out3$orig_pkts <-scale(x = datos.out3$orig_pkts, t.mn=0, t.mx=1)
#datos.out3$resp_pkts <-scale(x = datos.out3$resp_pkts, t.mn=0, t.mx=1)
#datos.out3$duration <-scale(x = datos.out3$duration, t.mn=0, t.mx=1)
library(scales)
datos.out3$duration <- rescale(datos.out3$duration)
datos.out3$orig_pkts <- rescale(datos.out3$orig_pkts)
datos.out3$resp_pkts <- rescale(datos.out3$resp_pkts)

summary(datos.out3)
str(datos.out3)


# Removemos registros duplicados

library(dplyr)
distinct(datos.out3) #8946 registros
data_unique <- datos.out3[!duplicated(datos.out3),]
data_unique

# Evaluando las variables categoricas
table(data_unique$proto)      # tcp, udp, icmp
table(data_unique$conn_state) # OTH, REJ, RSTOS0, RSTR, RSTRH, S0, SF, SH 
table(data_unique$label)      # Benign, Malicious

data<-datos.out3
datafast<-data_unique
# Creando variables dummies(one hot encoding)
#library(dummy)

#data = cbind(data, dummy(data$proto,sep = "_"))
#datacbind(data, dummy(data$conn_state,sep = "_"))

install.packages("fastDummies")
library('fastDummies')
data.dum1 <- dummy_cols(data, select_columns = 'proto')
data.dum2 <- dummy_cols(data.dum1, select_columns = 'conn_state')

# eliminamos la variable  
data$proto <- NULL
data$conn_state <- NULL

#Ordenamos las columnas
x = data[,c(1:5)]
y = data[,c(7:17)]
label = data[,c(6)]
data1<-cbind(x,y)
data1<-cbind(data1,label)

str(data1)
# Convertir a factor y recodificar la variable label
data1$label   <- as.factor(data1$label)



# La data est? balanceada
table(data1$label)
prop.table(table(data1$label))




#--------------------------------------------------------------
# Selecci?n de muestra de entrenamiento (70%) y 
#    de evaluaci?n (30%)
library(caret)
set.seed(123) 
index   <- createDataPartition(data1$label, 
                               p=0.7, list=FALSE)

train    <- data1[ index, ]
test  <- data1[-index, ]

# Verificando que se mantenga la proporci?n original
addmargins(table(data1$label))
round(prop.table(table(data1$label))*100,2)

addmargins(table(train$label))
round(prop.table(table(train$label))*100,2)

addmargins(table(test$label))
round(prop.table(table(test$label))*100,2)



######################################################
# ENTRENANDO CON REGRESION LOGISTICA, ARBOLES DE DECISION Y NAIVE BAYES #
######################################################
#--------------------------------------------------------------
# Definiendo los predictores y la variable objetivo (respuesta)
target     <- "label"
predictores <- setdiff(names(data1), target)
predictores

levels(data1$label)
pos <- levels(data1$label)[2]
pos

# Definiendo los training controls para m?ltiples modelos
fitControl <- trainControl(method = "cv",
                           number = 10,
                           savePredictions = 'final',
                           classProbs = T)


#--------------------------------------------------------------
# Entrenando con Naive Bayes
set.seed(123) 
modelo_nb<-train(train[,predictores],
                 train[,target],
                 method='nb',
                 trControl=fitControl,
                 tuneLength=3)

modelo_nb

# Prediciendo la clase en el test con Naive Bayes 
test$clase_nb<-predict(object = modelo_nb,test[,predictores])
head(test$clase_nb)

# Calculando indicadores de la matrizz de confusi?n con NB
cm_nb <- caret::confusionMatrix(test$clase_nb,
                                test[,target],
                                positive=pos)

cm_nb$byClass["Sensitivity"] 
cm_nb$byClass["Specificity"] 
cm_nb$overall["Accuracy"]

#-------------------------------------------------------------------
# Entrenando con Regresi?n Log?stica
set.seed(123) 
modelo_rl<-train(train[,predictores],
                 train[,target],
                 method='glm', family="binomial",
                 trControl=fitControl,
                 tuneLength=3)
modelo_rl

# Prediciendo la clase en el test con Regresi?n Log?stica
test$clase_rl<-predict(object = modelo_rl,test[,predictores])

# Calculando indicadores de la matriz de confusi?n con Log?stica
cm_rl <- caret::confusionMatrix(test$clase_rl,
                                test[,target],
                                positive=pos)

cm_rl$byClass["Sensitivity"] 
cm_rl$byClass["Specificity"] 
cm_rl$overall["Accuracy"]


#--------------------------------------------------------------
# Arbol de decision  con Bagging
set.seed(123) 
modelo_bg<-train(train[,predictores],
                 train[,target],
                 method='treebag',
                 trControl=fitControl,
                 tuneLength=3)
modelo_bg

# Prediciendo la clase en el test usando Bagging
test$clase_bg  <- predict(object = modelo_bg,test[,predictores])
head(test$clase_bg)

# Calculando indicadores de la matriz de confusi?n con Bagging
cm_bg <- caret::confusionMatrix(test$clase_bg,
                                test[,target],
                                positive=pos)

cm_bg$byClass["Sensitivity"] 
cm_bg$byClass["Specificity"] 
cm_bg$overall["Accuracy"]


#--------------------------------------------------------------
# Comparando el entrenamiento de los tres modelos
modelos  <- list(Arbol_Decision_Bagging = modelo_bg,
                 Naive_Bayes = modelo_nb,
                 Logistica   = modelo_rl)

comparacion_modelos <- resamples(modelos)
summary(comparacion_modelos)

dotplot(comparacion_modelos)

bwplot(comparacion_modelos)

densityplot(comparacion_modelos, 
            metric = "Accuracy",
            auto.key=TRUE)

#--------------------------------------------------------------
# Resumiendo y comparando los 3 algoritmos en el test
algoritmos       <- c("Arbol Decision","Naive Bayes","Log?stica")

sensibilidad  <- c(cm_knn$byClass["Sensitivity"],cm_nb$byClass["Sensitivity"],cm_rl$byClass["Sensitivity"])
especificidad <- c(cm_knn$byClass["Specificity"],cm_nb$byClass["Specificity"],cm_rl$byClass["Specificity"]) 
accuracy      <- c(accuracy_knn,accuracy_nb,accuracy_rl)

comparacion <- data.frame(algoritmos,sensibilidad, 
                          especificidad,accuracy)

comparacion